### 总结版

并发问题：
- 脏读 读到另一个事务未提交
- 不可重复读 读的过程中 另一个事务修改了数据 再次读读不到了
- 幻读  读的过程中，另一个事务新增了数据 再次读发现数目不一致
隔离级别：



### 序

要理解**隔离级别（Isolation Levels）**，首先需要知道并发事务会带来哪些**问题**。只有知道了痛点，才能理解不同级别的解决方案。

以下是详细的讲解，分为三个部分：**并发问题**、**隔离级别**、以及**MySQL中的特殊情况**。


### 第一部分：并发事务可能出现的问题

当多个事务（Transaction）同时操作数据库时，如果没有适当的隔离机制，就会出现以下几种数据不一致的问题：

#### 1. 脏读 (Dirty Read)
*   **定义**：事务A读取到了事务B**已经修改但尚未提交（Uncommitted）**的数据。
*   **场景**：
    1.  张三原本余额 100 元。
    2.  事务B开启，把张三余额改为 200 元（还未提交）。
    3.  事务A开启，读取张三余额，读到了 200 元。
    4.  事务B发现由于某种原因（如报错），执行了**回滚（Rollback）**，张三余额变回 100 元。
    5.  **结果**：事务A手里拿着的 200 元是一个不存在的“脏数据”，如果A用这个数据去操作，就会出错。

#### 2. 不可重复读 (Non-repeatable Read)
*   **定义**：在一个事务内，多次读取同一行数据，结果不一致。这是因为在两次读取之间，另一个事务**修改（Update）或删除**了该数据并提交了。
*   **场景**：
    1.  事务A开启，读取张三余额为 100 元。
    2.  事务B开启，把张三余额改为 200 元，并**提交（Commit）**。
    3.  事务A再次读取张三余额，发现变成了 200 元。
    4.  **结果**：事务A觉得自己还在同一个事务里，怎么刚才读还是100，现在变200了？（侧重于**修改**）。

#### 3. 幻读 (Phantom Read)
*   **定义**：在一个事务内，多次执行同一个查询（通常是范围查询），发现结果集的**数量**发生了变化。这是因为另一个事务**插入（Insert）**了新数据并提交了。
*   **场景**：
    1.  事务A查询“所有存款大于1000元的用户”，查到了 5 个人。
    2.  事务B插入了一个新用户，存款 2000 元，并**提交**。
    3.  事务A再次执行同样的查询，发现查到了 6 个人。
    4.  **结果**：事务A就像产生了幻觉一样，凭空多出了一行数据。（侧重于**新增**）。

---

### 第二部分：数据库的四种隔离级别

为了解决上述问题，SQL标准定义了四种隔离级别。级别越高，安全性越高，但性能（并发度）越低。

#### 1. 读未提交 (Read Uncommitted)
*   **解释**：允许一个事务读取另一个事务还没提交的数据。
*   **解决的问题**：无。
*   **存在的问题**：脏读、不可重复读、幻读。
*   **特点**：性能最好，但极不安全，基本不在生产环境使用。

#### 2. 读已提交 (Read Committed - RC)
*   **解释**：一个事务只能读取已经提交的数据。
*   **解决的问题**：**脏读**。
*   **存在的问题**：不可重复读、幻读。
*   **特点**：这是大多数数据库（如 Oracle, PostgreSQL, SQL Server）的**默认隔离级别**。它利用了 MVCC（多版本并发控制）机制，每次查询都会生成一个新的视图。

#### 3. 可重复读 (Repeatable Read - RR)
*   **解释**：确保在同一个事务中，多次读取同样的数据结果是一样的。
*   **解决的问题**：**脏读**、**不可重复读**。
*   **存在的问题**：标准SQL定义中，**幻读**依然存在（但在MySQL InnoDB中有所不同，见下文）。
*   **特点**：这是 **MySQL** 的**默认隔离级别**。事务启动时会生成一个全局快照，之后无论别的事务怎么改，当前事务看到的都是启动那一刻的状态。

#### 4. 串行化 (Serializable)
*   **解释**：最高的隔离级别。强制事务串行执行，就像单线程一样，一个接着一个排队做。
*   **解决的问题**：**所有并发问题**（脏读、不可重复读、幻读）。
*   **存在的问题**：性能极差，极易造成锁冲突和超时。
*   **特点**：只有在对数据一致性要求极其严格且并发量很小的场景下才使用。通常通过对读取的数据行加“共享锁”来实现。




